{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import models\n",
    "from sleep_classif.CNNmultitaper import ConvNetMultitaper\n",
    "from sleep_classif.LSTMConv import LSTM_Conv\n",
    "from sleep_classif.CNNadvanced import CNN_Advanced\n",
    "from sleep_classif.CNNmodel import SimpleCNN\n",
    "\n",
    "# import loaders and other functions\n",
    "from sleep_classif.preprocessing import compute_tapers\n",
    "from sleep_classif.dataloaders import MultiTaperSet, RawDataSet, FFT_Raw_DataSet\n",
    "from sleep_classif.trainer import Trainer\n",
    "\n",
    "# import from other librairies \n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Cuda\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K_fold indices generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_indices(set_size, n_folds = 5):\n",
    "    '''\n",
    "    return list of folds indices (train indices and  test indices)\n",
    "    '''\n",
    "    s = list(range(0, set_size))\n",
    "    random.shuffle(s)\n",
    "    s = [s[i::n_folds] for i in range(n_folds)]\n",
    "    folds = []\n",
    "    for i in range(n_folds):\n",
    "        test_set = np.array(s[i])\n",
    "        train_set = np.array([s[j] for j in range(n_folds) if i!=j]).ravel()\n",
    "        folds.append((train_set, test_set))\n",
    "    return(folds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold_indices(10, n_folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train basic CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = './data/raw_data/X_train.h5'\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "raw_train_set = RawDataSet(device=device,\n",
    "                                 data_path = data_path_train,\n",
    "                                 target_path = target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train with K_fold \n",
    "\n",
    "acc_fold_list = []\n",
    "n_folds = 5\n",
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "for n_fold, (train_indices, val_indices) in enumerate(k_fold_indices(len(raw_train_set), n_folds = n_folds)):\n",
    "        print(f\"fold number: {n_fold+1}\")\n",
    "        #instanciate a new model \n",
    "        simple_cnn = SimpleCNN().to(device)\n",
    "        optimizer = torch.optim.Adam(simple_cnn.parameters())\n",
    "\n",
    "        # creata data sets\n",
    "        train_set = torch.utils.data.dataset.Subset(raw_train_set,train_indices)\n",
    "        val_set = torch.utils.data.dataset.Subset(raw_train_set,val_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # instanciate trainer\n",
    "        trainer = Trainer(simple_cnn,\n",
    "                        nn.CrossEntropyLoss(),\n",
    "                        optimizer,\n",
    "                        train_loader,\n",
    "                        device,\n",
    "                        valid_data_loader = val_loader,\n",
    "                        class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))\n",
    "\n",
    "        # train model\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "        for epoch in range(0,n_epochs):\n",
    "                loss, accuracy = trainer.train_epoch()\n",
    "                if epoch == n_epochs-1:\n",
    "                        acc_fold_list.append(accuracy)\n",
    "\n",
    "# return mean accuracy\n",
    "accuracy = np.mean(acc_fold_list)\n",
    "print(f\"K_fold average accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN + Multitaper Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create MultiTapers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_tapers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_eeg_path_train = './data/pre_processed_data/Multitaper_eeg_train.npy'\n",
    "features_position_path_train = './data/pre_processed_data/Multitaper_position_train.npy'\n",
    "\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "taper_train_set = MultiTaperSet(device=device,\n",
    "                                features_eeg_path = features_eeg_path_train,\n",
    "                                features_position_path = features_position_path_train,\n",
    "                                target_path = target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train with K_fold \n",
    "\n",
    "acc_fold_list = []\n",
    "n_folds = 5\n",
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "for n_fold, (train_indices, val_indices) in enumerate(k_fold_indices(len(taper_train_set), n_folds = n_folds)):\n",
    "        print(f\"fold number: {n_fold+1}\")\n",
    "        #instanciate a new model \n",
    "        CNN_taper_model = ConvNetMultitaper().to(device)\n",
    "        optimizer = torch.optim.Adam(CNN_taper_model.parameters())\n",
    "\n",
    "        # creata data sets\n",
    "        train_set = torch.utils.data.dataset.Subset(taper_train_set,train_indices)\n",
    "        val_set = torch.utils.data.dataset.Subset(taper_train_set,val_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # instanciate trainer\n",
    "        trainer = Trainer(CNN_taper_model,\n",
    "                        nn.CrossEntropyLoss(),\n",
    "                        optimizer,\n",
    "                        train_loader,\n",
    "                        device,\n",
    "                        valid_data_loader = val_loader,\n",
    "                        class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))\n",
    "\n",
    "        # train model\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "        for epoch in range(0,n_epochs):\n",
    "                loss, accuracy = trainer.train_epoch()\n",
    "                if epoch == n_epochs-1:\n",
    "                        acc_fold_list.append(accuracy)\n",
    "\n",
    "# return mean accuracy\n",
    "accuracy = np.mean(acc_fold_list)\n",
    "print(f\"K_fold average accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training an advanced CNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import fftpack\n",
    "\n",
    "data_path_train = './data/raw_data/X_train.h5'\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "\n",
    "\n",
    "raw_train_set = FFT_Raw_DataSet(device=device,\n",
    "                                 data_path = data_path_train,\n",
    "                                 target_path = target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train with K_fold \n",
    "\n",
    "acc_fold_list = []\n",
    "n_folds = 5\n",
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "num_classes = 5\n",
    "raw_feat, fft_feat, raw_pos_feat, fft_pos_feat = 5,5,3,3\n",
    "\n",
    "for n_fold, (train_indices, val_indices) in enumerate(k_fold_indices(len(raw_train_set), n_folds = n_folds)):\n",
    "        print(f\"fold number: {n_fold+1}\")\n",
    "        #instanciate a new model \n",
    "        CNN_Advanced_model = CNN_Advanced(raw_feat, fft_feat, raw_pos_feat, fft_pos_feat, num_classes, 0.5).to(device)\n",
    "        optimizer = torch.optim.Adam(CNN_Advanced_model.parameters())\n",
    "\n",
    "        # creata data sets\n",
    "        train_set = torch.utils.data.dataset.Subset(raw_train_set,train_indices)\n",
    "        val_set = torch.utils.data.dataset.Subset(raw_train_set,val_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # instanciate trainer\n",
    "        trainer = Trainer(CNN_Advanced_model,\n",
    "                        nn.CrossEntropyLoss(),\n",
    "                        optimizer,\n",
    "                        train_loader,\n",
    "                        device,\n",
    "                        valid_data_loader = val_loader,\n",
    "                        class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))\n",
    "\n",
    "        # train model\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "        for epoch in range(0,n_epochs):\n",
    "                loss, accuracy = trainer.train_epoch()\n",
    "                if epoch == n_epochs-1:\n",
    "                        acc_fold_list.append(accuracy)\n",
    "\n",
    "# return mean accuracy\n",
    "accuracy = np.mean(acc_fold_list)\n",
    "print(f\"K_fold average accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path_train = './data/raw_data/X_train.h5'\n",
    "\n",
    "target_path = './data/raw_data/y_train.csv'\n",
    "\n",
    "\n",
    "\n",
    "raw_train_set = RawDataSet(device=device,\n",
    "                                 data_path = data_path_train,\n",
    "                                 target_path = target_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### train with K_fold \n",
    "\n",
    "acc_fold_list = []\n",
    "n_folds = 5\n",
    "n_epochs = 30\n",
    "batch_size = 64\n",
    "\n",
    "raw_feat = raw_train_set.feature_shape()\n",
    "num_classes = 5\n",
    "\n",
    "for n_fold, (train_indices, val_indices) in enumerate(k_fold_indices(len(raw_train_set), n_folds = n_folds)):\n",
    "        print(f\"fold number: {n_fold+1}\")\n",
    "        #instanciate a new model \n",
    "        LSTM_Conv_model = LSTM_Conv(raw_feat, num_classes).to(device)\n",
    "        optimizer = torch.optim.Adam(LSTM_Conv_model.parameters())\n",
    "\n",
    "        # creata data sets\n",
    "        train_set = torch.utils.data.dataset.Subset(raw_train_set,train_indices)\n",
    "        val_set = torch.utils.data.dataset.Subset(raw_train_set,val_indices)\n",
    "\n",
    "        train_loader = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = torch.utils.data.DataLoader(val_set, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "        # instanciate trainer\n",
    "        trainer = Trainer(LSTM_Conv_model,\n",
    "                        nn.CrossEntropyLoss(),\n",
    "                        optimizer,\n",
    "                        train_loader,\n",
    "                        device,\n",
    "                        valid_data_loader = val_loader,\n",
    "                        class_weights=torch.Tensor([8.081897,22.222222, 2.756846, 3.765060, 4.927727]))\n",
    "\n",
    "        # train model\n",
    "        loss_list = []\n",
    "        accuracy_list = []\n",
    "        for epoch in range(0,n_epochs):\n",
    "                loss, accuracy = trainer.train_epoch()\n",
    "                if epoch == n_epochs-1:\n",
    "                        acc_fold_list.append(accuracy)\n",
    "\n",
    "# return mean accuracy\n",
    "accuracy = np.mean(acc_fold_list)\n",
    "print(f\"K_fold average accuracy: {accuracy}\")"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "conda-env-python38-py",
   "name": "common-cu110.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m87"
  },
  "interpreter": {
   "hash": "90400e2509a7f97e1574e9e217fc898b753a8c591c8f81400b72bc0569fd4fc5"
  },
  "kernelspec": {
   "display_name": "Python [conda env:python38]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
